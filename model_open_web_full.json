{
    "block_size": 1024,
    "batch_size": 33,
    "grad_accum": 2,
    "num_epochs": 6,
    "model_name": "gpt2",
    "vocab_size": 50257,
    "n_positions": 1024,
    "n_embed": 768,
    "n_layer": 12,
    "n_head": 12,
    "dataset_name": "openwebtext",
    "dataset_split": "train",
    "learning_rate": 1e-4,
    "weight_decay": 0.01,
    "warmup_steps": 1000,
    "checkpoint_path": "model_open_web_full_checkpoint.pt",
    "cache_path": "model_open_web_full",
    "max_new_tokens": 400,
    "max_response_length": 150,
    "temperature": 0.9,
    "top_p": 0.8,
    "num_samples": 8000000,
    "chunk_size": 8000
}
